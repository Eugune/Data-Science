{"cells":[{"cell_type":"markdown","metadata":{"id":"WUcVUrwYWf7m"},"source":["# Exercises\n","### 3. The *width and depth* of the algorithm. Add as many additional layers as you need to reach 5 hidden layers. Moreover, adjust the width of the algorithm as you find suitable. How does the validation accuracy change? What about the time it took the algorithm to train?\n","\n","**Solution**\n","\n","This exercise is pretty much the same as the previous one. However, it will get us to a much deeper net. As we noted in the previous exercise, you a deeeper net may need to be wider to produce better results.\n","\n","We tried with 1000 hidden units in each layer and 5 hidden layers.\n","\n","The result (as you can see below) is that our **model's training was going very well,** until it *overfit*. It did so by quite a lot.\n","\n","It took my personal computer around 5-6 minutes to train the model.\n","\n","What if you have more epochs?"]},{"cell_type":"markdown","source":["1.   3 hidden laywers and 150 layers size  \n","    Epoch 1/5 - 12s - loss: 0.2760 - accuracy: 0.9177 val_accuracy: 0.9622  \n","    Epoch 5/5 - 3s - loss: 0.0438 - accuracy: 0.9864 val_accuracy: 0.9838\n","2.   4 hidden laywers and 400 layers size      \n","    Epoch 1/5 - 13s - loss: 0.2255 - accuracy: 0.9320 val_accuracy: 0.9650  \n","    Epoch 5/5 - 3s - loss: 0.0413 - accuracy: 0.9867 val_accuracy: 0.9860  \n","3.   5 hidden laywers and 700 layers size  (overfit occur)  \n","    Epoch 1/5 - 13s - loss: 0.2351 - accuracy: 0.9289 val_accuracy: 0.9597   \n","    Epoch 3/5 - 5s - loss: 0.0800 - accuracy: 0.9776 val_accuracy: 0.9805   \n","    Epoch 4/5 - 4s - loss: 0.0587 - accuracy: ***0.9830*** val_accuracy: ***0.9842***  \n","    Epoch 5/5 - 6s - loss: 0.0518 - accuracy: ***0.9848*** val_accuracy: ***0.9793***  \n","4.   5 hidden laywers and 1000 layers size  (overfit occur)    \n","    Epoch 1/5 - 13s - loss: 0.2351 - accuracy: 0.9300 val_accuracy: 0.9645  \n","    Epoch 2/5 - 4s - loss: 0.1082 - accuracy: 0.9700 val_accuracy: 0.9750  \n","    Epoch 3/5 - 7s - loss: 0.0788 - accuracy: 0.9773 val_accuracy: 0.9765  \n","    Epoch 4/5 - 5s - loss: 0.0643 - accuracy: 0.9821 val_accuracy: 0.9815  \n","    Epoch 5/5 - 4s - loss: 0.0595 - accuracy: 0.9841 val_accuracy: 0.9745  \n","5.   ----   \n","    Epoch 1/5 - 14s - loss: 0.2348 - accuracy: 0.9277 val_accuracy: 0.9657  \n","    Epoch 5/5 - 4s - loss: 0.0493 - accuracy: 0.9856 val_accuracy: 0.9832\n","6.   ----   \n","    Epoch 1/5 - 24s - loss: 0.2138 - accuracy: 0.9357 val_accuracy: 0.9687  \n","    Epoch 5/5 - 12s - loss: 0.0299 - accuracy: 0.9903 val_accuracy: 0.9843  \n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"yGhtgEr4iSkG"}},{"cell_type":"markdown","metadata":{"id":"opEXZPXyWf7u"},"source":["# Deep Neural Network for MNIST Classification\n","\n","The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs).\n","\n","The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image).\n","\n","The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes.\n","\n","Our goal would be to build a neural network with 2 hidden layers."]},{"cell_type":"markdown","metadata":{"id":"4djpx5a9Wf7v"},"source":["## Import the relevant packages"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Jg31g_6-Wf7x","executionInfo":{"status":"ok","timestamp":1701038405011,"user_tz":300,"elapsed":6471,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","import tensorflow_datasets as tfds\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YmiDs46QWf70"},"source":["## Data\n","\n","That's where we load and preprocess our data."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["51f66aa94306486ba734f0218fc9dc67","c6284bf0b74c446ea04a5e539b17ed9c","9eccdd45b3174c2093d295f7f91a735d","9159fb7a10f54936be564811a6eefb4b","fe9f964ba7da480fb3c70fab1698f77a","b1655a23ec2342b3bc48ca68072711ea","172dd44780df43ffb405b23de193a582","5d8d80de6e42495297600bb548bed654","2abb1d6a3bc843dd8964447eb00815a4","2cd6a568fbb849e3962cb1e30b7df837","fd2f2f4edd3e4ff9b05985acdfcdadf1"]},"id":"hkFJLw5vWf71","executionInfo":{"status":"ok","timestamp":1701038413334,"user_tz":300,"elapsed":8328,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}},"outputId":"9e42f616-a090-4521-f59a-b1fea4533911"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\n"]},{"output_type":"display_data","data":{"text/plain":["Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51f66aa94306486ba734f0218fc9dc67"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\n"]}],"source":["\n","mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n","\n","mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n","\n","num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n","num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n","\n","num_test_samples = mnist_info.splits['test'].num_examples\n","num_test_samples = tf.cast(num_test_samples, tf.int64)\n","\n","\n","def scale(image, label):\n","    image = tf.cast(image, tf.float32)\n","    image /= 255.\n","\n","    return image, label\n","\n","scaled_train_and_validation_data = mnist_train.map(scale)\n","test_data = mnist_test.map(scale)\n","\n","\n","BUFFER_SIZE = 10000\n","\n","shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n","validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n","train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n","\n","\n","BATCH_SIZE = 100\n","\n","train_data = train_data.batch(BATCH_SIZE)\n","validation_data = validation_data.batch(num_validation_samples)\n","test_data = test_data.batch(num_test_samples)\n","\n","validation_inputs, validation_targets = next(iter(validation_data))"]},{"cell_type":"markdown","metadata":{"id":"9SnvqgUOWf72"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"7N-oQzcFWf73"},"source":["### Outline the model\n","When thinking about a deep learning algorithm, we mostly imagine building the model. So, let's do it :)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qsbRYn4-Wf75","executionInfo":{"status":"ok","timestamp":1701038413629,"user_tz":300,"elapsed":305,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}}},"outputs":[],"source":["input_size = 784\n","output_size = 10\n","\n","hidden_layer_size = 1000\n","\n","model = tf.keras.Sequential([\n","\n","    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\n","\n","    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n","    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n","    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n","    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n","    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 3rd hidden layer\n","    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 4th hidden layer\n","    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 5th hidden layer\n","\n","    # the final layer is no different, we just make sure to activate it with softmax\n","    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n","])"]},{"cell_type":"markdown","metadata":{"id":"W4TXL8XEWf76"},"source":["### Choose the optimizer and the loss function"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FCTbFUs3Wf77","executionInfo":{"status":"ok","timestamp":1701038413963,"user_tz":300,"elapsed":336,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}}},"outputs":[],"source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"jFIKUmkjWf78"},"source":["### Training\n","That's where we train the model we have built."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_Ga5kC2Wf78","executionInfo":{"status":"ok","timestamp":1701038445967,"user_tz":300,"elapsed":32008,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}},"outputId":"79a2eb75-6b14-4c2e-cf59-7959c4164d16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","540/540 - 14s - loss: 0.2391 - accuracy: 0.9280 - val_loss: 0.1276 - val_accuracy: 0.9675 - 14s/epoch - 26ms/step\n","Epoch 2/5\n","540/540 - 4s - loss: 0.1072 - accuracy: 0.9695 - val_loss: 0.1087 - val_accuracy: 0.9743 - 4s/epoch - 7ms/step\n","Epoch 3/5\n","540/540 - 4s - loss: 0.0795 - accuracy: 0.9774 - val_loss: 0.0749 - val_accuracy: 0.9823 - 4s/epoch - 7ms/step\n","Epoch 4/5\n","540/540 - 4s - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.0572 - val_accuracy: 0.9850 - 4s/epoch - 8ms/step\n","Epoch 5/5\n","540/540 - 4s - loss: 0.0506 - accuracy: 0.9860 - val_loss: 0.0604 - val_accuracy: 0.9855 - 4s/epoch - 7ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7aab9b426590>"]},"metadata":{},"execution_count":5}],"source":["NUM_EPOCHS = 5\n","\n","model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose =2)"]},{"cell_type":"markdown","metadata":{"id":"tTNEjWodWf7-"},"source":["## Test the model\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KICjgVGYWf7_","executionInfo":{"status":"ok","timestamp":1701038446744,"user_tz":300,"elapsed":779,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}},"outputId":"c64dcf62-f25c-43cf-8840-6a9bb9342321"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 795ms/step - loss: 0.0948 - accuracy: 0.9772\n","Test loss: 0.09. Test accuracy: 97.72%\n"]}],"source":["test_loss, test_accuracy = model.evaluate(test_data)\n","print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"]},{"cell_type":"markdown","source":["1.   3 hidden laywers and 150 layers size  \n","    Epoch 1/5 - 12s - loss: 0.2760 - accuracy: 0.9177 val_accuracy: 0.9622  \n","    Epoch 5/5 - 3s - loss: 0.0438 - accuracy: 0.9864 val_accuracy: 0.9838\n","2.   4 hidden laywers and 400 layers size      \n","    Epoch 1/5 - 13s - loss: 0.2255 - accuracy: 0.9320 val_accuracy: 0.9650  \n","    Epoch 5/5 - 3s - loss: 0.0413 - accuracy: 0.9867 val_accuracy: 0.9860  \n","3.   5 hidden laywers and 700 layers size  (overfit occur)  \n","    Epoch 1/5 - 13s - loss: 0.2351 - accuracy: 0.9289 val_accuracy: 0.9597   \n","    Epoch 3/5 - 5s - loss: 0.0800 - accuracy: 0.9776 val_accuracy: 0.9805   \n","    Epoch 4/5 - 4s - loss: 0.0587 - accuracy: ***0.9830*** val_accuracy: ***0.9842***  \n","    Epoch 5/5 - 6s - loss: 0.0518 - accuracy: ***0.9848*** val_accuracy: ***0.9793***  \n","4.   5 hidden laywers and 1000 layers size  (overfit occur)    \n","    Epoch 1/5 - 13s - loss: 0.2351 - accuracy: 0.9300 val_accuracy: 0.9645  \n","    Epoch 2/5 - 4s - loss: 0.1082 - accuracy: 0.9700 val_accuracy: 0.9750  \n","    Epoch 3/5 - 7s - loss: 0.0788 - accuracy: 0.9773 val_accuracy: 0.9765  \n","    Epoch 4/5 - 5s - loss: 0.0643 - accuracy: 0.9821 val_accuracy: 0.9815  \n","    Epoch 5/5 - 4s - loss: 0.0595 - accuracy: 0.9841 val_accuracy: 0.9745  \n","5.   ----   \n","    Epoch 1/5 - 14s - loss: 0.2348 - accuracy: 0.9277 val_accuracy: 0.9657  \n","    Epoch 5/5 - 4s - loss: 0.0493 - accuracy: 0.9856 val_accuracy: 0.9832\n","6.   ----   \n","    Epoch 1/5 - 24s - loss: 0.2138 - accuracy: 0.9357 val_accuracy: 0.9687  \n","    Epoch 5/5 - 12s - loss: 0.0299 - accuracy: 0.9903 val_accuracy: 0.9843  \n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"2PfXmqpWe-HP"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"51f66aa94306486ba734f0218fc9dc67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6284bf0b74c446ea04a5e539b17ed9c","IPY_MODEL_9eccdd45b3174c2093d295f7f91a735d","IPY_MODEL_9159fb7a10f54936be564811a6eefb4b"],"layout":"IPY_MODEL_fe9f964ba7da480fb3c70fab1698f77a"}},"c6284bf0b74c446ea04a5e539b17ed9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1655a23ec2342b3bc48ca68072711ea","placeholder":"​","style":"IPY_MODEL_172dd44780df43ffb405b23de193a582","value":"Dl Completed...: 100%"}},"9eccdd45b3174c2093d295f7f91a735d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d8d80de6e42495297600bb548bed654","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2abb1d6a3bc843dd8964447eb00815a4","value":5}},"9159fb7a10f54936be564811a6eefb4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cd6a568fbb849e3962cb1e30b7df837","placeholder":"​","style":"IPY_MODEL_fd2f2f4edd3e4ff9b05985acdfcdadf1","value":" 5/5 [00:00&lt;00:00, 15.13 file/s]"}},"fe9f964ba7da480fb3c70fab1698f77a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1655a23ec2342b3bc48ca68072711ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"172dd44780df43ffb405b23de193a582":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d8d80de6e42495297600bb548bed654":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2abb1d6a3bc843dd8964447eb00815a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cd6a568fbb849e3962cb1e30b7df837":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd2f2f4edd3e4ff9b05985acdfcdadf1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}