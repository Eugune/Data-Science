{"cells":[{"cell_type":"markdown","metadata":{"id":"xyVh0fuNigKF"},"source":["# Exercises\n","\n","### 4. Fiddle with the activation functions. Try applying sigmoid transformation to both layers. The sigmoid activation is given by the method: tf.nn.sigmoid()\n","\n","**Solution**\n","\n","Find the part where we stack layers (Sequential()).\n","\n","Adjust the activations from 'relu' to 'sigmoid'.\n","    \n","Generally, we should **reach an inferior solution. That is because relu 'cleans' the noise in the data** (think about it - if a value is negative, relu filters it out, while if it is positive, it takes it into account). For the MNIST dataset, we care only about the intensely black and white parts in the images of the digits, so such filtering proves beneficial.\n","\n","**The sigmoid does not filter the signals as well as relu, but still reaches a respectable result (around 95%).**\n","\n","**Try using softmax activations for all layers. How does the result change? Can you explain why that happens?**\n","\n","The accuracy will reach an inferior solution and even worser than using 'sigmoid'\n","\n"," The softmax function ***squashes input values to a probability distribution***, which means the output values sum to 1. **This property is suitable for the output layer **of a neural network where you want to obtain probabilities for ***different classes.***\n","\n"," Loss of Information:\n"," Difficulty in Training\n"," Reduced Capacity for Representation\n"," Non-Negativity and Sum Constraint"]},{"cell_type":"markdown","source":["\n","\n","1.   layers size 50 , 2 hidden layer, activation func = relu  \n","    Epoch 1/5 - 12s - loss: 0.4274 - accuracy: 0.8777 val_accuracy: 0.9323  \n","    Epoch 5/5 - 6s - loss: 0.0930 - accuracy: 0.9719 val_accuracy: 0.9748\n","\n","2.   layers size 50 , 2 hidden layer, activation func = sigmoid  \n","    Epoch 1/5 - 13s - loss: 0.9970 - accuracy: 0.7859 val_accuracy: 0.9017  \n","    Epoch 5/5 - 4s - loss: 0.1702 - accuracy: 0.9510 val_accuracy: 0.9537\n","\n","2.   layers size 50 , 2 hidden layer, activation func = softmax for all   \n","    Epoch 1/5 - 16s - loss: 2.1969 - accuracy: 0.3836 val_accuracy: 0.6665  \n","    Epoch 5/5 - 4s - loss: 0.7911 - accuracy: 0.6817 val_accuracy: 0.6863\n","  "],"metadata":{"id":"kAxdsAK21msl"}},{"cell_type":"markdown","metadata":{"id":"g0SBfUT5igKG"},"source":["# Deep Neural Network for MNIST Classification\n","\n","The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs).\n","\n","The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image).\n","\n","The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes.\n","\n","Our goal would be to build a neural network with 2 hidden layers."]},{"cell_type":"markdown","metadata":{"id":"3K0wjQ4oigKH"},"source":["## Import the relevant packages"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6rwmMLenigKH","executionInfo":{"status":"ok","timestamp":1701039133410,"user_tz":300,"elapsed":6157,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","import tensorflow_datasets as tfds\n","\n"]},{"cell_type":"markdown","metadata":{"id":"icLSTx2KigKJ"},"source":["## Data\n","\n","That's where we load and preprocess our data."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MtL6LW5YigKJ","executionInfo":{"status":"ok","timestamp":1701039137829,"user_tz":300,"elapsed":4428,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}}},"outputs":[],"source":["\n","mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n","\n","mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n","\n","num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n","num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n","\n","num_test_samples = mnist_info.splits['test'].num_examples\n","num_test_samples = tf.cast(num_test_samples, tf.int64)\n","\n","\n","def scale(image, label):\n","    image = tf.cast(image, tf.float32)\n","    image /= 255.\n","\n","    return image, label\n","\n","scaled_train_and_validation_data = mnist_train.map(scale)\n","test_data = mnist_test.map(scale)\n","\n","\n","BUFFER_SIZE = 10000\n","\n","shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n","validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n","train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n","\n","\n","BATCH_SIZE = 100\n","\n","train_data = train_data.batch(BATCH_SIZE)\n","validation_data = validation_data.batch(num_validation_samples)\n","test_data = test_data.batch(num_test_samples)\n","\n","validation_inputs, validation_targets = next(iter(validation_data))"]},{"cell_type":"markdown","metadata":{"id":"33jGXZhrigKJ"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"IPwxWVS7igKJ"},"source":["### Outline the model\n","When thinking about a deep learning algorithm, we mostly imagine building the model. So, let's do it :)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"q3ynWsImigKJ","executionInfo":{"status":"ok","timestamp":1701039137969,"user_tz":300,"elapsed":149,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}}},"outputs":[],"source":["input_size = 784\n","output_size = 10\n","\n","hidden_layer_size = 50\n","\n","model = tf.keras.Sequential([\n","\n","    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\n","\n","    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n","    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n","    tf.keras.layers.Dense(hidden_layer_size, activation='softmax'), # 1st hidden layer\n","    tf.keras.layers.Dense(hidden_layer_size, activation='softmax'), # 2nd hidden layer\n","    # tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 3rd hidden layer\n","    # tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 4th hidden layer\n","    # tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 5th hidden layer\n","\n","    # the final layer is no different, we just make sure to activate it with softmax\n","    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n","])"]},{"cell_type":"markdown","metadata":{"id":"L0fdSwkMigKJ"},"source":["### Choose the optimizer and the loss function"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"jn3WHhjSigKK","executionInfo":{"status":"ok","timestamp":1701039137969,"user_tz":300,"elapsed":2,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}}},"outputs":[],"source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"WJOJ3QTUigKK"},"source":["### Training\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCJ2OR_RigKK","executionInfo":{"status":"ok","timestamp":1701039170513,"user_tz":300,"elapsed":32546,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}},"outputId":"e5f41a19-4994-4cb1-802d-9cc8971a9dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","540/540 - 16s - loss: 2.1969 - accuracy: 0.3836 - val_loss: 1.9796 - val_accuracy: 0.6665 - 16s/epoch - 30ms/step\n","Epoch 2/5\n","540/540 - 4s - loss: 1.6254 - accuracy: 0.6652 - val_loss: 1.2954 - val_accuracy: 0.6722 - 4s/epoch - 7ms/step\n","Epoch 3/5\n","540/540 - 4s - loss: 1.1071 - accuracy: 0.6715 - val_loss: 0.9688 - val_accuracy: 0.6773 - 4s/epoch - 6ms/step\n","Epoch 4/5\n","540/540 - 4s - loss: 0.8946 - accuracy: 0.6766 - val_loss: 0.8309 - val_accuracy: 0.6845 - 4s/epoch - 7ms/step\n","Epoch 5/5\n","540/540 - 4s - loss: 0.7911 - accuracy: 0.6817 - val_loss: 0.7580 - val_accuracy: 0.6863 - 4s/epoch - 8ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a68fbfff970>"]},"metadata":{},"execution_count":5}],"source":["NUM_EPOCHS = 5\n","\n","model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose =2)"]},{"cell_type":"markdown","metadata":{"id":"hMl04kkjigKK"},"source":["## Test the model\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwZ53IVSigKL","executionInfo":{"status":"ok","timestamp":1701039171286,"user_tz":300,"elapsed":776,"user":{"displayName":"Eugene L","userId":"13757838802534143234"}},"outputId":"de4c83a8-5a54-42cf-c806-95bcd62a7a6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 780ms/step - loss: 0.7606 - accuracy: 0.6798\n","Test loss: 0.76. Test accuracy: 67.98%\n"]}],"source":["test_loss, test_accuracy = model.evaluate(test_data)\n","print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"]},{"cell_type":"markdown","source":["\n","\n","1.   layers size 50 , 2 hidden layer, activation func = relu  \n","    Epoch 1/5 - 12s - loss: 0.4274 - accuracy: 0.8777 val_accuracy: 0.9323  \n","    Epoch 5/5 - 6s - loss: 0.0930 - accuracy: 0.9719 val_accuracy: 0.9748\n","\n","2.   layers size 50 , 2 hidden layer, activation func = sigmoid  \n","    Epoch 1/5 - 13s - loss: 0.9970 - accuracy: 0.7859 val_accuracy: 0.9017  \n","    Epoch 5/5 - 4s - loss: 0.1702 - accuracy: 0.9510 val_accuracy: 0.9537\n","\n","2.   layers size 50 , 2 hidden layer, activation func = softmax for all   \n","    Epoch 1/5 - 16s - loss: 2.1969 - accuracy: 0.3836 val_accuracy: 0.6665  \n","    Epoch 5/5 - 4s - loss: 0.7911 - accuracy: 0.6817 val_accuracy: 0.6863\n","  \n","\n","\n"],"metadata":{"id":"MkCzFG6gzRD7"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}